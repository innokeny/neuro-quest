{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5642181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "from typing import NamedTuple, TypedDict\n",
    "\n",
    "from rich import print\n",
    "from rich.table import Table\n",
    "\n",
    "from treelib import Tree # type: ignore\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, # type: ignore\n",
    "    AutoTokenizer, # type: ignore\n",
    "    TrainingArguments, # type: ignore\n",
    "    Trainer, # type: ignore\n",
    "    BitsAndBytesConfig, # type: ignore\n",
    "    DataCollatorForLanguageModeling, # type: ignore\n",
    ")\n",
    "\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b81816",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "074ca5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen3-1.7B\"\n",
    "DATA_DIR = Path(\"../dataset/dump/short-fantasy-quests\")\n",
    "\n",
    "MODEL_SAVE_DIR = Path(\"../models/llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a11f8e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert DATA_DIR.exists() and DATA_DIR.is_dir()\n",
    "\n",
    "if not MODEL_SAVE_DIR.exists():\n",
    "    MODEL_SAVE_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff73c54",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4974c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees: list[Tree] = [joblib.load(f) for f in DATA_DIR.iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da048460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                   Basic data counts                    </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Name                             </span>┃<span style=\"font-weight: bold\"> Value             </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Number of trees                  │ 9                 │\n",
       "│ Total number of nodes            │ 461               │\n",
       "│ Count non empty nodes            │ 362               │\n",
       "│ Average number of nodes per tree │ 51.22222222222222 │\n",
       "└──────────────────────────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                   Basic data counts                    \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mName                            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue            \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Number of trees                  │ 9                 │\n",
       "│ Total number of nodes            │ 461               │\n",
       "│ Count non empty nodes            │ 362               │\n",
       "│ Average number of nodes per tree │ 51.22222222222222 │\n",
       "└──────────────────────────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = Table(title=\"Basic data counts\")\n",
    "table.add_column(\"Name\")\n",
    "table.add_column(\"Value\")\n",
    "\n",
    "table.add_row(\"Number of trees\", str(len(trees)))\n",
    "table.add_row(\"Total number of nodes\", str(sum(len(tree) for tree in trees)))\n",
    "table.add_row(\"Count non empty nodes\", str(sum(len(list(tree.filter_nodes(lambda n: n.data['text'] is not None and n.data['text'] != \"\"))) for tree in trees if len(tree) > 0)))\n",
    "table.add_row(\"Average number of nodes per tree\", str(sum(len(tree) for tree in trees) / len(trees)))\n",
    "\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89ba3ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Triplet(NamedTuple):\n",
    "    context: str\n",
    "    statement: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ce7fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplets(tree: Tree, nid: str) -> list[Triplet]:\n",
    "    current = tree.get_node(nid)\n",
    "    if current is None:\n",
    "        return []\n",
    "    children = tree.children(nid)\n",
    "    triplets: list[Triplet] = []\n",
    "    for child in children:\n",
    "        triplet = Triplet(\n",
    "            context=current.data['text'],\n",
    "            statement=child.tag,\n",
    "            answer=child.data['text']\n",
    "        )\n",
    "        if triplet.context is not None and triplet.context != \"\" and triplet.statement is not None and triplet.statement != \"\" and triplet.answer is not None and triplet.answer != \"\": \n",
    "            triplets.append(triplet)\n",
    "    return triplets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17c460f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = []\n",
    "for tree in trees:\n",
    "    for node in tree.nodes:\n",
    "        triplets.extend(get_triplets(tree, node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "192b78a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Number of Triplets: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">337</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Number of Triplets: \u001b[1;36m337\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Number of Triplets: {len(triplets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d9d237c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DatasetDict</span><span style=\"font-weight: bold\">({</span>\n",
       "    train: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dataset</span><span style=\"font-weight: bold\">({</span>\n",
       "        features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'response'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        num_rows: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">303</span>\n",
       "    <span style=\"font-weight: bold\">})</span>\n",
       "    test: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dataset</span><span style=\"font-weight: bold\">({</span>\n",
       "        features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'response'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        num_rows: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span>\n",
       "    <span style=\"font-weight: bold\">})</span>\n",
       "<span style=\"font-weight: bold\">})</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDatasetDict\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "    train: \u001b[1;35mDataset\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "        features: \u001b[1m[\u001b[0m\u001b[32m'prompt'\u001b[0m, \u001b[32m'response'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        num_rows: \u001b[1;36m303\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "    test: \u001b[1;35mDataset\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "        features: \u001b[1m[\u001b[0m\u001b[32m'prompt'\u001b[0m, \u001b[32m'response'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        num_rows: \u001b[1;36m34\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def triplet2train(triplet: Triplet) -> dict:\n",
    "    return dict(prompt=f\"[CONTEXT] {triplet.context} [STATEMENT] {triplet.statement}\", response=triplet.answer)\n",
    "\n",
    "dataset = Dataset.from_list([triplet2train(triplet) for triplet in triplets]).train_test_split(0.1)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337728aa",
   "metadata": {},
   "source": [
    "### Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9985071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87c671e662146c4a52d50ea5d9f095c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/9.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fcca01c65dd422cbc1c14569d004a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5900aeb4b2d14e82aa03a392ebd5cbd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59ef959b81a4cf9b6e436bb8b4dc89f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eba533a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4fa2c4b9c6344acb7fc8bfcf0b8a4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd1593c73ae4a9f82b7b962286359f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e122c6cd0b45bb9a5e475c8b9ad4b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f725f25a8494480935d0fcfb0e533a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/622M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8de2d16caa443980dfcc41e39979dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea2fbd41dee45bf92e95a2aafe49075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d38d946be8452d86685945baa1f5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=bnb_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "580969d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_and_tokenize(examples):\n",
    "    texts = [\n",
    "        f\"[im_start]system\\nYOU ARE Dungeon Master[im_end]\\n\"\n",
    "        f\"[im_start]user\\n{str(prompt)}[im_end]\\n\"\n",
    "        f\"[im_start]assistant\\n{str(response)}[im_end]\"\n",
    "        for prompt, response in zip(examples['prompt'], examples['response'])\n",
    "    ]\n",
    "\n",
    "    tokenized = tokenizer(\n",
    "        texts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=False\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": tokenized[\"input_ids\"].tolist(),\n",
    "        \"attention_mask\": tokenized[\"attention_mask\"].tolist(),\n",
    "        \"labels\": tokenized[\"input_ids\"].tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f30b53de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774cb21769cf44b08f9c1a9da0f2279c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Formatting and tokenizing:   0%|          | 0/303 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc886f7a8204600bfb0de29aa72f40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Formatting and tokenizing:   0%|          | 0/34 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "    format_and_tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=[\"prompt\", \"response\"],\n",
    "    desc=\"Formatting and tokenizing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ba2823f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,605,632 || all params: 1,722,180,608 || trainable%: 0.0932\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee8454ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_SAVE_DIR,\n",
    "    per_device_train_batch_size=4,  # Увеличен размер батча (если позволяет память GPU)\n",
    "    gradient_accumulation_steps=2,  # Увеличена аккумуляция градиентов\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=100,\n",
    "    fp16=True,\n",
    "    optim=\"adamw_bnb_8bit\",  # Более эффективный оптимизатор\n",
    "    save_strategy=\"steps\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    report_to=\"none\",\n",
    "    gradient_checkpointing=False,  # Отключено для ускорения\n",
    "    load_best_model_at_end=True,\n",
    "    remove_unused_columns=True,\n",
    "    label_names=[\"labels\"],\n",
    "    max_grad_norm=0.3,\n",
    "    dataloader_num_workers=2,  # Параллельная загрузка данных\n",
    "    torch_compile=False  # Компиляция графа вычислений\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae57690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    "    pad_to_multiple_of=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65e8317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6681679c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained(MODEL_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76e62cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_action(context: str, action: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "[im_start]system\n",
    "YOU ARE Dungeon Master[im_end]\n",
    "[im_start]user [CONTEXT] {context} [STATEMENT] {action}[im_end]\n",
    "[im_start]assistant\n",
    "\"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=500,\n",
    "        temperature=0.9,\n",
    "        top_p=0.8,\n",
    "        repetition_penalty=1.1,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return full_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17e6fa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "system\n",
       "YOU ARE Dungeon Master\n",
       "user <span style=\"font-weight: bold\">[</span>CONTEXT<span style=\"font-weight: bold\">]</span> Earlier, the player stole a coin from a tavern <span style=\"font-weight: bold\">[</span>STATEMENT<span style=\"font-weight: bold\">]</span> I went into the tavern\n",
       "assistant\n",
       "You are in the tavern. You're not the only one who's here<span style=\"color: #808000; text-decoration-color: #808000\">...</span> There's a group of three men with swords around their \n",
       "necks, holding a table hostage. The first man is a lanky youth with a longsword and a red cloak that looks like it \n",
       "might be a disguise. He says, <span style=\"color: #008000; text-decoration-color: #008000\">\"We've been waiting for you to come out and make your move.\"</span> They have the look of \n",
       "bandits. Wait<span style=\"color: #808000; text-decoration-color: #808000\">...</span> Are they trying to rob me? Or just doing their own thing?\n",
       "\n",
       "Wait, this was an easy job. That coin is worth a good ten gold pieces, even if they don't give me enough time to \n",
       "get out of town on foot. But as I'm thinking, my eyes catch something: the first man has a small object hidden \n",
       "under his cloak—maybe he’s hiding a weapon or a letter? It could help us figure out what to do next.\n",
       "\n",
       "\n",
       "assistant\n",
       "The scene continues with tension in the tavern. As the trio of men approach, the atmosphere thickens with unease. \n",
       "They’re ready to strike at any moment. My instincts kick in. I quickly assess the situation and decide to act fast \n",
       "before they take more than a few coins. I pull out my satchel and start counting the gold coins I can collect. The \n",
       "moment I open it, I see a handful of coins, but also notice a small item tucked inside—their leader is holding a \n",
       "small, ornate box. \n",
       "\n",
       "Suddenly, the first man notices the item and demands, <span style=\"color: #008000; text-decoration-color: #008000\">\"What's that?\"</span> His voice drops lower. “That's our prize.” He \n",
       "leans closer, whispering, “Don’t let them know where we’re going. Keep the rest of the coins until you can get \n",
       "away.” The second man grins, “Then maybe we’ll be able to find a better place to stay tonight.”\n",
       "\n",
       "As I continue the conversation, I ask them about their motives and the reasons behind their actions. The first man \n",
       "speaks up, saying, “We’ve taken some money from the local shopkeeper. We were looking for a place to hide our goods\n",
       "when they found us.” This explanation seems plausible, yet there's still an air of uncertainty around the group. I \n",
       "think back to my earlier encounter with the coin, wondering how much value it holds compared to what I’m currently \n",
       "carrying. It feels like a small step toward freedom, especially since I need to leave this place soon. But the \n",
       "question remains: will these\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "system\n",
       "YOU ARE Dungeon Master\n",
       "user \u001b[1m[\u001b[0mCONTEXT\u001b[1m]\u001b[0m Earlier, the player stole a coin from a tavern \u001b[1m[\u001b[0mSTATEMENT\u001b[1m]\u001b[0m I went into the tavern\n",
       "assistant\n",
       "You are in the tavern. You're not the only one who's here\u001b[33m...\u001b[0m There's a group of three men with swords around their \n",
       "necks, holding a table hostage. The first man is a lanky youth with a longsword and a red cloak that looks like it \n",
       "might be a disguise. He says, \u001b[32m\"We've been waiting for you to come out and make your move.\"\u001b[0m They have the look of \n",
       "bandits. Wait\u001b[33m...\u001b[0m Are they trying to rob me? Or just doing their own thing?\n",
       "\n",
       "Wait, this was an easy job. That coin is worth a good ten gold pieces, even if they don't give me enough time to \n",
       "get out of town on foot. But as I'm thinking, my eyes catch something: the first man has a small object hidden \n",
       "under his cloak—maybe he’s hiding a weapon or a letter? It could help us figure out what to do next.\n",
       "\n",
       "\n",
       "assistant\n",
       "The scene continues with tension in the tavern. As the trio of men approach, the atmosphere thickens with unease. \n",
       "They’re ready to strike at any moment. My instincts kick in. I quickly assess the situation and decide to act fast \n",
       "before they take more than a few coins. I pull out my satchel and start counting the gold coins I can collect. The \n",
       "moment I open it, I see a handful of coins, but also notice a small item tucked inside—their leader is holding a \n",
       "small, ornate box. \n",
       "\n",
       "Suddenly, the first man notices the item and demands, \u001b[32m\"What's that?\"\u001b[0m His voice drops lower. “That's our prize.” He \n",
       "leans closer, whispering, “Don’t let them know where we’re going. Keep the rest of the coins until you can get \n",
       "away.” The second man grins, “Then maybe we’ll be able to find a better place to stay tonight.”\n",
       "\n",
       "As I continue the conversation, I ask them about their motives and the reasons behind their actions. The first man \n",
       "speaks up, saying, “We’ve taken some money from the local shopkeeper. We were looking for a place to hide our goods\n",
       "when they found us.” This explanation seems plausible, yet there's still an air of uncertainty around the group. I \n",
       "think back to my earlier encounter with the coin, wondering how much value it holds compared to what I’m currently \n",
       "carrying. It feels like a small step toward freedom, especially since I need to leave this place soon. But the \n",
       "question remains: will these\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(generate_action(\n",
    "    context=\"Earlier, the player stole a coin from a tavern\",\n",
    "    action=\"I went into the tavern\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba828ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
